import csv
import os
import subprocess
import re
import argparse
import fnmatch  

# Config
TESTCASE_DIR = "../../testcases" 
INPUT_EXT = ".in"
OUTPUT_EXT = ".out"

# Max external restarts. If the solver fails to find a solution, 
K_MAX = 10          

# Helpers

def run_sa(test_id):
    """
    Executes: ./sa -test <id>
    """
    exe = "../src/sa"
    if os.name == 'nt': exe = "../src/sa.exe"
    
    if not os.path.exists(exe):
        print(f"[Error] Solver {exe} not found!")
        return False

    cmd = [exe, "-test", str(test_id)]

    try:
        # Run SA, suppressing stdout/stderr to keep console clean
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except subprocess.CalledProcessError:
        return False

def check_result_is_yes(test_id):
    """
    Parses the .out file generated by the solver. 
    Returns True only if the first line is "yes".
    """
    output_path = os.path.join(TESTCASE_DIR, f"{test_id}{OUTPUT_EXT}")

    if not os.path.exists(output_path):
        return False

    try:
        with open(output_path, 'r') as f:
            first_line = f.readline().strip().lower()
            return first_line == "yes"
    except Exception:
        return False

def get_file_ids(patterns):
    """
    Resolves a list of file IDs based on input patterns.
    Supports keywords like 'scan' or wildcards like 'dp_*'.
    """
    if not os.path.exists(TESTCASE_DIR):
        print(f"[Error] Testcase directory '{TESTCASE_DIR}' not found.")
        return []
    
    # Get all base filenames 
    all_files = [f[:-len(INPUT_EXT)] for f in os.listdir(TESTCASE_DIR) if f.endswith(INPUT_EXT)]
    
    final_ids = set()

    for pattern in patterns:
        # 'scan' or '*' gets everything
        if pattern.lower() == 'scan' or pattern == '*':
            final_ids.update(all_files)
            continue
        
        # Handle wildcards
        if '*' in pattern or '?' in pattern:
            matched = fnmatch.filter(all_files, pattern)
            if not matched:
                print(f"[Warning] Pattern '{pattern}' matched no files.")
            final_ids.update(matched)
        else:
            # Exact match
            if pattern in all_files:
                final_ids.add(pattern)
            else:
                print(f"[Warning] ID '{pattern}' not found in {TESTCASE_DIR}")

    # Natural sort to fix order 
    def natural_sort_key(s):
        return [int(text) if text.isdigit() else text.lower()
                for text in re.split('([0-9]+)', s)]
    
    sorted_ids = sorted(list(final_ids), key=natural_sort_key)
    return sorted_ids

# CSV Setup
def init_csv(output_csv):
    # Create parent dir if it doesn't exist
    output_dir = os.path.dirname(output_csv)
    if output_dir and not os.path.exists(output_dir):
        try:
            os.makedirs(output_dir)
        except Exception as e:
            print(f"[Error] Failed to create directory {output_dir}: {e}")
            return False

    try:
        with open(output_csv, "w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(
                [
                    "instance_id",
                    "selected_groups",
                    "power_list",
                    "first_success_restart",
                    "success_flag",
                ]
            )
        print(f"[Info] CSV initialized at: {output_csv}")
        return True
    except Exception as e:
        print(f"[Error] Failed to initialize CSV: {e}")
        return False

# SA Restart Loop
def test_sa_on_files(file_ids, output_csv):
    print(f"\nSA Restart Test Started (K_MAX={K_MAX})")
    print(f"Target Directory: {TESTCASE_DIR}")
    print(f"Selected Cases: {len(file_ids)}")
    print("-" * 60)
    
    results = []

    for idx, test_id in enumerate(file_ids):
        first_success = -1
        success_flag = False

        # Attempt to run SA multiple times until it succeeds
        for k in range(1, K_MAX + 1):
            # Run binary
            run_sa(test_id)
            
            # Check output file
            if check_result_is_yes(test_id):
                first_success = k
                success_flag = True
                break
        
        # Prepare data 
        dummy_groups = "[]"
        dummy_power = "[]"
        
        row_data = [test_id, dummy_groups, dummy_power, first_success, success_flag]
        results.append(row_data)
        
        status = "SUCCESS" if success_flag else "FAILURE"
        # Progress log
        print(f"[{idx+1}/{len(file_ids)}] ID: {test_id:<10} -> {status} (Restarts: {first_success if success_flag else '-'})")

        # Write to CSV immediately (append mode) to save data if script crashes
        try:
            with open(output_csv, "a", newline="") as f:
                writer = csv.writer(f)
                writer.writerow(row_data)
        except Exception as e:
            print(f"[Warning] Failed to write row to CSV: {e}")

    return results

def main():
    parser = argparse.ArgumentParser(description="SA Restart Robustness Test")
    parser.add_argument("--ns", nargs="+", required=True, 
                        help="List of Test IDs, wildcards (e.g. dp1_*), or 'scan' for all.")
    parser.add_argument("--outcsv", default="sa_restart_distribution.csv", 
                        help="Output CSV path (e.g., results/my_sa.csv)")
    
    args = parser.parse_args()

    # Resolve IDs
    ids = get_file_ids(args.ns)
    
    if not ids:
        print("[Error] No valid test files found matching your criteria.")
        return

    # Setup CSV (overwrite old file, write header)
    if not init_csv(args.outcsv):
        return

    # Run tests (writes real-time)
    test_sa_on_files(ids, args.outcsv)
    
    print(f"\nDone. Results saved to {args.outcsv}")

if __name__ == "__main__":
    main()