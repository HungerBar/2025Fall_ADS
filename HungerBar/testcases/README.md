This folder `testcases/` stores integer array data for testing various algorithms. The datasets are categorized and generated based on different algorithms and testing purposes. The characteristics and uses of each data type are detailed below.

## 1. DFS Series Data

**Generation Script**: `dfsGenerator.py`
**Purpose**: Test the performance of DFS + pruning algorithms under extreme conditions.

All elements are generated within the range `[maxv/3, maxv/2]` with minor perturbations of ±3. This results in elements that are very close to each other, making sorting or fast pruning strategies ineffective. Elements are completely randomly shuffled to eliminate regular structures, meaning DFS will perceive potential success at most nodes and can barely perform early pruning. The results are close to the worst-case scenarios for DFS, making this series ideal for stress-testing algorithm performance.

## 2. DP Series Data

### dp1_i.in

**Purpose**: Generate integer arrays with variable a and fixed n.

**File Format**
First line: Array length n
Second line: The generated integer array

### dp2_i.in

**Purpose**: Generate integer arrays with variable n and a fixed total sum.

**File Format**
First line: Array length n
Second line: The generated integer array

### dp3_i.in

**Purpose**: Generate random arrays of length n for testing the time complexity of DP algorithms.

Elements fluctuate around an average value (`mean ± noise`), simulating real-world data distributions. The script supports multiple values of n and repeated generation.

**File Format**
First line: Array length n
Second line: The generated integer array

## 3. SA Series Data

#### Base Building Way

**Generation Script**: `BaseGen.py`
**Purpose**: Generate small, strictly solvable base arrays for subsequent combination into medium/large-scale, high-difficulty test data.

The old algorithms (`./dp` + `./check`) are used to verify the solvability of each array, ensuring every base array is strictly partitionable. These small arrays can be combined randomly and scaled randomly to generate medium/large arrays, simulating complex scenarios or creating high-difficulty test cases. This series is suitable for comprehensive testing of algorithms such as Simulated Annealing (SA) and greedy algorithms, ensuring solvability while increasing combinatorial complexity.

**File Format**
Small array files: `base_1.txt ~ base_20.txt`
Each file contains one strictly solvable small array.

Combined medium/large array files: `sa1_1.in ~ sa1_10000.in`
Generated by combining multiple base arrays with random scaling, used for large-scale algorithm testing and performance evaluation.

#### Greedy Building Way

**Generation Script**: `GreedyGen.py`
**Purpose**: Generate large-scale arrays that are guaranteed to be partitionable into three equal parts, suitable for greedy algorithm testing.

By default, the script generates a large number of arrays with length 1000. Elements are within the range `[MIN_VALUE, MAX_VALUE]`, and the total sum is divisible by 3 to ensure solvability. Basic information for each instance (array length, target bucket sum, minimum/maximum values, average value, file name, generation time) is recorded in a CSV file.

**File Format**
Array files: `sa_1.in ~ sa_1000.in`
